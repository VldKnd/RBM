## Elementary functions
An RBM can be represented by an object/structure containing a field W (weight matrix linking visible variables to hidden variables), a field a (bias of input units) and a field b (bias of output units)
A neural network (DNN) and a Deep Belief Network (DBN) can be represented by a list of RBMs, the size of this list being equal to the number of hidden layers of the network (+ classifying layer in the case of the DNN). Each element of this list will therefore coincide with an RBM and will contain a field W (weight matrix linking 2 consecutive layers), a field a (bias of the input units which coincide with the estimated variational parameters, except for the first layer) and a field b.
Here is a list of functions that will allow to build/learn neural network.
### Building an RBM and testing on Binary AlphaDigits
A main_RBM_alpha script allows you to learn the characters of the Binary AlphaDigits database of your choice via an RBM and to generate characters similar to those learned. The construction of this program requires the following functions:
* read_alpha_digit function that retrieves data in matrix form (row data, column pixels) and takes as argument the characters (or their index 0, - - - , 35) to "learn".
* init_RBM allowing to build and initialize the weights and biases of an RBM. This function will return an RBM structure with initialized weights and biases. The biases will be initialized to 0 while the weights will be initialized randomly according to a centered normal distribution, with a variance equal to 0.01.
* input_output_RBM function that takes an RBM structure and input data as arguments and returns the value of the output units calculated from the sigmoid function.
* output_input_RBM function that takes as arguments an RBM, output data and returns the value of the input units from the sigmoid function.
* train_RBM function that learns an RBM from the Contrastive-Divergence-1 algorithm in a non supervised manner. This function will return an RBM structure and will take as arguments an RBM structure, the number of iterations of the gradient descent (epochs), the learning rate, the size
of the mini-batch, input data... At the end of each gradient iteration, the squared error between the input data and the data reconstructed from the hidden unit will be displayed to measure the reconstruction power of the RBM.
* generer_image_RBM generates samples following an RBM. This function will return and display the generated images and will take as arguments an RBM structure, the number of iterations to use in the Gibbs sampler and the number of images to generate.